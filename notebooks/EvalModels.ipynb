{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0e09589-b5bd-4d22-8bee-9de86a322e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import evaluate  # instead of datasets.load_metric\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "from datasets import Dataset\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9529743e-607a-4742-9668-d75fcbd3521b",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d73ea62c-7ebf-474b-ada5-29096317cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(member: str, test_size: float = 0.2, seed: int = 42, data_path: str = '/work/users/s/m/smerrill/Albemarle/dataset') -> Tuple[List[dict], List[dict]]:\n",
    "    \"\"\"\n",
    "    Splits the dataset into training and test sets. Synthetic data is always added to the training set.\n",
    "\n",
    "    Parameters:\n",
    "    - member: The name identifier for the board member.\n",
    "    - test_size: Proportion of the real (non-synthetic) data to include in the test split.\n",
    "    - seed: Random seed for reproducibility.\n",
    "    - data_path: Base directory for the dataset files.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple (train_data, test_data)\n",
    "    \"\"\"\n",
    "    real_data, synth_data = [], []\n",
    "\n",
    "    if member == 'kateacuff':\n",
    "        real_data = np.load(os.path.join(data_path, 'kateacuff_train.npy'))\n",
    "        synth_data = np.load(os.path.join(data_path, 'synth_kateacuff.npy'))\n",
    "        test_data = np.load(os.path.join(data_path, 'kateacuff_test.npy'), allow_pickle=True)\n",
    "        train_completion_data = np.load(os.path.join(data_path, 'kateacuff_train_completion.npy'), allow_pickle=True)\n",
    "\n",
    "        \n",
    "    elif member == 'ellenosborne':\n",
    "        real_data = np.load(os.path.join(data_path, 'ellenosborne_train.npy'))\n",
    "        synth_data = np.load(os.path.join(data_path, 'synth_ellenosborne.npy'))\n",
    "        test_data = np.load(os.path.join(data_path, 'ellenosborne_test.npy'), allow_pickle=True)\n",
    "        train_completion_data = np.load(os.path.join(data_path, 'ellenosborne_train_completion.npy'), allow_pickle=True)\n",
    "        \n",
    "    elif member == 'grahampaige':\n",
    "        real_data = np.load(os.path.join(data_path, 'grahampaige_train.npy'))\n",
    "        synth_data = np.load(os.path.join(data_path, 'synth_grahampaige.npy'))\n",
    "        test_data = np.load(os.path.join(data_path, 'grahampaige_test.npy'), allow_pickle=True)\n",
    "        train_completion_data = np.load(os.path.join(data_path, 'grahampaige_train_completion.npy'), allow_pickle=True)                             \n",
    "        \n",
    "    elif member == 'judyle':\n",
    "        real_data = np.load(os.path.join(data_path, 'judyle_train.npy'))\n",
    "        synth_data = np.load(os.path.join(data_path, 'synth_judyle.npy'))\n",
    "        test_data = np.load(os.path.join(data_path, 'judyle_test.npy'), allow_pickle=True)\n",
    "        train_completion_data = np.load(os.path.join(data_path, 'judyle_train_completion.npy'), allow_pickle=True)\n",
    "        \n",
    "    elif member == 'katrinacallsen':\n",
    "        real_data = np.load(os.path.join(data_path, 'katrinacallsen_train.npy'))\n",
    "        test_data = np.load(os.path.join(data_path, 'katrinacallsen_test.npy'), allow_pickle=True)\n",
    "        train_completion_data = np.load(os.path.join(data_path, 'katrinacallsen_train_completion.npy'), allow_pickle=True)\n",
    "        \n",
    "    elif member == 'davidoberg':\n",
    "        real_data = np.load(os.path.join(data_path, 'davidoberg_train.npy'))\n",
    "        test_data = np.load(os.path.join(data_path, 'davidoberg_test.npy'), allow_pickle=True)\n",
    "        train_completion_data = np.load(os.path.join(data_path, 'davidoberg_train_completion.npy'), allow_pickle=True)\n",
    "        \n",
    "    elif member == 'jonnoalcaro':\n",
    "        real_data = np.load(os.path.join(data_path, 'jonnoalcaro_train.npy'))\n",
    "        test_data = np.load(os.path.join(data_path, 'jonnoalcaro_test.npy'), allow_pickle=True)\n",
    "        train_completion_data = np.load(os.path.join(data_path, 'jonnoalcaro_train_completion.npy'), allow_pickle=True)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown member: {member}\")\n",
    "\n",
    "    if not 0 < test_size < 1:\n",
    "        raise ValueError(\"test_size must be a float between 0 and 1.\")\n",
    "\n",
    "    train_data = list(real_data) + list(synth_data)\n",
    "    return train_data, test_data, train_completion_data\n",
    "\n",
    "\n",
    "def compute_metrics(generated_texts, reference_texts):\n",
    "\n",
    "    # Compute metrics\n",
    "    bleu_score = bleu.compute(predictions=generated_texts, references=[[r] for r in reference_texts])\n",
    "    rouge_score = rouge.compute(predictions=generated_texts, references=reference_texts)\n",
    "    bertscore_result = bertscore.compute(predictions=generated_texts, references=reference_texts, lang=\"en\")\n",
    "\n",
    "    # Average BERTScore F1\n",
    "    avg_bertscore_f1 = sum(bertscore_result['f1']) / len(bertscore_result['f1'])\n",
    "            \n",
    "    return bleu_score, rouge_score, bertscore_result, avg_bertscore_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35677dc5-b2ce-4e2b-b82e-4e3a3462dc6e",
   "metadata": {},
   "source": [
    "### Eval Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420b67ba-198c-41f6-9552-45d512b63ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "285bedbf-b145-4861-8681-9b045c44892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_path = '/work/users/s/m/smerrill/Albemarle/trained_models/'\n",
    "trained_models = os.listdir(trained_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc71cb21-fd58-4b71-a061-be7b9ccfda95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = {}\n",
    "for model in trained_models:\n",
    "    model_path = os.path.join(trained_path, model)\n",
    "    has_npy = any(f.endswith('.npy') for f in  os.listdir(model_path))\n",
    "    if not has_npy:\n",
    "        continue\n",
    "\n",
    "    model_result_dict = {}\n",
    "    for f in os.listdir(model_path):\n",
    "        if f.endswith('.npy'):\n",
    "            dataset = f.split('_')[0]\n",
    "            train_or_test = f.split('_')[1]\n",
    "            tmp = np.load(os.path.join(model_path, f))\n",
    "\n",
    "            model_result_dict[dataset+ '_' + train_or_test ] = tmp\n",
    "    model_results[model] = model_result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5590974-b73d-4689-bd46-7cd35f8708be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bertscore = evaluate.load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f330c4fe-894a-4a14-b29c-e13048aea863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['davidoberg_4', 'davidoberg_8', 'ellenosborne_4', 'ellenosborne_8', 'grahampaige_4', 'grahampaige_8', 'jonnoalcaro_4', 'judyle_4', 'judyle_8', 'kateacuff_4', 'kateacuff_8', 'katrinacallsen_4', 'katrinacallsen_8'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9226d18-bd0e-4244-b0be-65aa348d767f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "davidoberg_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: test\n",
      "BLEU: 0.0060\n",
      "ROUGE-L: 0.0740\n",
      "BERTScore F1: 0.7558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: train\n",
      "BLEU: 0.0138\n",
      "ROUGE-L: 0.0940\n",
      "BERTScore F1: 0.8023\n",
      "davidoberg_8\n",
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: test\n",
      "BLEU: 0.0079\n",
      "ROUGE-L: 0.0561\n",
      "BERTScore F1: 0.7814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: train\n",
      "BLEU: 0.0119\n",
      "ROUGE-L: 0.0843\n",
      "BERTScore F1: 0.7883\n",
      "ellenosborne_4\n",
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: test\n",
      "BLEU: 0.0000\n",
      "ROUGE-L: 0.0571\n",
      "BERTScore F1: 0.7762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: train\n",
      "BLEU: 0.0122\n",
      "ROUGE-L: 0.0869\n",
      "BERTScore F1: 0.7834\n",
      "ellenosborne_8\n",
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: test\n",
      "BLEU: 0.0058\n",
      "ROUGE-L: 0.0714\n",
      "BERTScore F1: 0.7830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: train\n",
      "BLEU: 0.0141\n",
      "ROUGE-L: 0.0949\n",
      "BERTScore F1: 0.7956\n",
      "grahampaige_4\n",
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: test\n",
      "BLEU: 0.0048\n",
      "ROUGE-L: 0.0574\n",
      "BERTScore F1: 0.7786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: train\n",
      "BLEU: 0.0144\n",
      "ROUGE-L: 0.0936\n",
      "BERTScore F1: 0.7968\n",
      "grahampaige_8\n",
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: test\n",
      "BLEU: 0.0070\n",
      "ROUGE-L: 0.0869\n",
      "BERTScore F1: 0.8060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: train\n",
      "BLEU: 0.0174\n",
      "ROUGE-L: 0.1040\n",
      "BERTScore F1: 0.8051\n",
      "jonnoalcaro_4\n",
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: test\n",
      "BLEU: 0.0000\n",
      "ROUGE-L: 0.0504\n",
      "BERTScore F1: 0.7728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: train\n",
      "BLEU: 0.0122\n",
      "ROUGE-L: 0.0867\n",
      "BERTScore F1: 0.7915\n",
      "judyle_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: test\n",
      "BLEU: 0.0064\n",
      "ROUGE-L: 0.0710\n",
      "BERTScore F1: 0.7543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: train\n",
      "BLEU: 0.0127\n",
      "ROUGE-L: 0.0891\n",
      "BERTScore F1: 0.7849\n",
      "judyle_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: test\n",
      "BLEU: 0.0077\n",
      "ROUGE-L: 0.0756\n",
      "BERTScore F1: 0.7149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: train\n",
      "BLEU: 0.0130\n",
      "ROUGE-L: 0.0891\n",
      "BERTScore F1: 0.7813\n",
      "kateacuff_4\n",
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: test\n",
      "BLEU: 0.0000\n",
      "ROUGE-L: 0.0785\n",
      "BERTScore F1: 0.8010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: train\n",
      "BLEU: 0.0133\n",
      "ROUGE-L: 0.0907\n",
      "BERTScore F1: 0.7838\n",
      "kateacuff_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: test\n",
      "BLEU: 0.0000\n",
      "ROUGE-L: 0.0439\n",
      "BERTScore F1: 0.6754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: train\n",
      "BLEU: 0.0113\n",
      "ROUGE-L: 0.0794\n",
      "BERTScore F1: 0.7418\n",
      "katrinacallsen_4\n",
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: test\n",
      "BLEU: 0.0054\n",
      "ROUGE-L: 0.0688\n",
      "BERTScore F1: 0.7886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: train\n",
      "BLEU: 0.0150\n",
      "ROUGE-L: 0.1036\n",
      "BERTScore F1: 0.8059\n",
      "katrinacallsen_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: test\n",
      "BLEU: 0.0000\n",
      "ROUGE-L: 0.0871\n",
      "BERTScore F1: 0.7674\n",
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: train\n",
      "BLEU: 0.0139\n",
      "ROUGE-L: 0.1017\n",
      "BERTScore F1: 0.7885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "verbose = True\n",
    "metrics_list = []\n",
    "\n",
    "for model in model_results.keys():\n",
    "    generations = model_results[model]\n",
    "    print(model)\n",
    "    for dataset in generations.keys():\n",
    "        dataset_name = dataset.split('_')[0]\n",
    "        train_or_test = dataset.split('_')[1]\n",
    "        _, test_data, train_completion_data = train_test_split(dataset_name)\n",
    "        \n",
    "        if train_or_test == 'train':\n",
    "            data = train_completion_data\n",
    "        elif train_or_test == 'test':\n",
    "            data = test_data\n",
    "        else:\n",
    "            print(\"Train or Test not Valid: \", train_or_test)\n",
    "            continue\n",
    "            \n",
    "        reference_texts = [x['completion'] for x in data]\n",
    "        generated_texts = generations[dataset]\n",
    "        bleu_score, rouge_score, bertscore_result, avg_bertscore_f1 = compute_metrics(generated_texts, reference_texts)\n",
    "        \n",
    "        metrics_list.append({\n",
    "            \"ModelName\": model,\n",
    "            \"dataset\": dataset_name,\n",
    "            \"split\": train_or_test,\n",
    "            \"BLEU\": bleu_score[\"bleu\"],\n",
    "            \"ROUGE-L\": rouge_score[\"rougeL\"],\n",
    "            \"BERTScore_F1\": avg_bertscore_f1\n",
    "        })\n",
    "\n",
    "        if verbose:\n",
    "            print(\"\\n--- Evaluation Results ---\")\n",
    "            print(f\"Dataset: {dataset_name}\")\n",
    "            print(f\"Split: {train_or_test}\")\n",
    "            print(f\"BLEU: {bleu_score['bleu']:.4f}\")\n",
    "            print(f\"ROUGE-L: {rouge_score['rougeL']:.4f}\")\n",
    "            print(f\"BERTScore F1: {avg_bertscore_f1:.4f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7246feb7-3a1d-480b-a7b8-6d70fe45d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "def88d6e-c644-49e0-9383-6a3200ba1f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ModelName</th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>ROUGE-L</th>\n",
       "      <th>BERTScore_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>grahampaige_8</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>train</td>\n",
       "      <td>0.017418</td>\n",
       "      <td>0.103957</td>\n",
       "      <td>0.805140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>katrinacallsen_4</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>train</td>\n",
       "      <td>0.014960</td>\n",
       "      <td>0.103601</td>\n",
       "      <td>0.805933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>katrinacallsen_8</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>train</td>\n",
       "      <td>0.013902</td>\n",
       "      <td>0.101667</td>\n",
       "      <td>0.788458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ellenosborne_8</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>train</td>\n",
       "      <td>0.014099</td>\n",
       "      <td>0.094899</td>\n",
       "      <td>0.795604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>davidoberg_4</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>train</td>\n",
       "      <td>0.013788</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.802275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>grahampaige_4</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>train</td>\n",
       "      <td>0.014401</td>\n",
       "      <td>0.093623</td>\n",
       "      <td>0.796828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>kateacuff_4</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>train</td>\n",
       "      <td>0.013283</td>\n",
       "      <td>0.090736</td>\n",
       "      <td>0.783802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>judyle_4</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>train</td>\n",
       "      <td>0.012728</td>\n",
       "      <td>0.089104</td>\n",
       "      <td>0.784895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>judyle_8</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>train</td>\n",
       "      <td>0.012968</td>\n",
       "      <td>0.089081</td>\n",
       "      <td>0.781303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ellenosborne_4</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>train</td>\n",
       "      <td>0.012199</td>\n",
       "      <td>0.086862</td>\n",
       "      <td>0.783410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>jonnoalcaro_4</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>train</td>\n",
       "      <td>0.012153</td>\n",
       "      <td>0.086679</td>\n",
       "      <td>0.791533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>davidoberg_8</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>train</td>\n",
       "      <td>0.011915</td>\n",
       "      <td>0.084270</td>\n",
       "      <td>0.788251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>kateacuff_8</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>train</td>\n",
       "      <td>0.011275</td>\n",
       "      <td>0.079368</td>\n",
       "      <td>0.741832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ModelName    dataset  split      BLEU   ROUGE-L  BERTScore_F1\n",
       "11     grahampaige_8  kateacuff  train  0.017418  0.103957      0.805140\n",
       "23  katrinacallsen_4  kateacuff  train  0.014960  0.103601      0.805933\n",
       "25  katrinacallsen_8  kateacuff  train  0.013902  0.101667      0.788458\n",
       "7     ellenosborne_8  kateacuff  train  0.014099  0.094899      0.795604\n",
       "1       davidoberg_4  kateacuff  train  0.013788  0.094017      0.802275\n",
       "9      grahampaige_4  kateacuff  train  0.014401  0.093623      0.796828\n",
       "19       kateacuff_4  kateacuff  train  0.013283  0.090736      0.783802\n",
       "15          judyle_4  kateacuff  train  0.012728  0.089104      0.784895\n",
       "17          judyle_8  kateacuff  train  0.012968  0.089081      0.781303\n",
       "5     ellenosborne_4  kateacuff  train  0.012199  0.086862      0.783410\n",
       "13     jonnoalcaro_4  kateacuff  train  0.012153  0.086679      0.791533\n",
       "3       davidoberg_8  kateacuff  train  0.011915  0.084270      0.788251\n",
       "21       kateacuff_8  kateacuff  train  0.011275  0.079368      0.741832"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.split=='train'].sort_values('ROUGE-L', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0bdd959-0a76-4028-ab4f-c6af08849e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ModelName</th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>ROUGE-L</th>\n",
       "      <th>BERTScore_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>grahampaige_8</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>test</td>\n",
       "      <td>0.007012</td>\n",
       "      <td>0.086935</td>\n",
       "      <td>0.805978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>kateacuff_4</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>test</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078454</td>\n",
       "      <td>0.800979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>katrinacallsen_4</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>test</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>0.068802</td>\n",
       "      <td>0.788590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ellenosborne_8</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>test</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>0.071436</td>\n",
       "      <td>0.782972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>No-FineTuning</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>test</td>\n",
       "      <td>0.006077</td>\n",
       "      <td>0.100115</td>\n",
       "      <td>0.781960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>davidoberg_8</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>test</td>\n",
       "      <td>0.007942</td>\n",
       "      <td>0.056078</td>\n",
       "      <td>0.781399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>grahampaige_4</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>test</td>\n",
       "      <td>0.004844</td>\n",
       "      <td>0.057371</td>\n",
       "      <td>0.778644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ellenosborne_4</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>test</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057121</td>\n",
       "      <td>0.776156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>jonnoalcaro_4</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>test</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050421</td>\n",
       "      <td>0.772840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>katrinacallsen_8</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>test</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087073</td>\n",
       "      <td>0.767417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>davidoberg_4</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>test</td>\n",
       "      <td>0.005951</td>\n",
       "      <td>0.073997</td>\n",
       "      <td>0.755838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>judyle_4</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>test</td>\n",
       "      <td>0.006355</td>\n",
       "      <td>0.071005</td>\n",
       "      <td>0.754252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>judyle_8</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>test</td>\n",
       "      <td>0.007682</td>\n",
       "      <td>0.075580</td>\n",
       "      <td>0.714888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>kateacuff_8</td>\n",
       "      <td>kateacuff</td>\n",
       "      <td>test</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043945</td>\n",
       "      <td>0.675437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ModelName    dataset split      BLEU   ROUGE-L  BERTScore_F1\n",
       "10     grahampaige_8  kateacuff  test  0.007012  0.086935      0.805978\n",
       "18       kateacuff_4  kateacuff  test  0.000000  0.078454      0.800979\n",
       "22  katrinacallsen_4  kateacuff  test  0.005441  0.068802      0.788590\n",
       "6     ellenosborne_8  kateacuff  test  0.005798  0.071436      0.782972\n",
       "26     No-FineTuning  kateacuff  test  0.006077  0.100115      0.781960\n",
       "2       davidoberg_8  kateacuff  test  0.007942  0.056078      0.781399\n",
       "8      grahampaige_4  kateacuff  test  0.004844  0.057371      0.778644\n",
       "4     ellenosborne_4  kateacuff  test  0.000000  0.057121      0.776156\n",
       "12     jonnoalcaro_4  kateacuff  test  0.000000  0.050421      0.772840\n",
       "24  katrinacallsen_8  kateacuff  test  0.000000  0.087073      0.767417\n",
       "0       davidoberg_4  kateacuff  test  0.005951  0.073997      0.755838\n",
       "14          judyle_4  kateacuff  test  0.006355  0.071005      0.754252\n",
       "16          judyle_8  kateacuff  test  0.007682  0.075580      0.714888\n",
       "20       kateacuff_8  kateacuff  test  0.000000  0.043945      0.675437"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.split=='test'].sort_values('BERTScore_F1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8fadc7d5-e2d7-4286-8291-52f42beabc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_score, rouge_score, bertscore_result, avg_bertscore_f1 = ({'bleu': 0.006077129561234383,\n",
    "  'precisions': [0.15736934820904286,\n",
    "   0.011876484560570071,\n",
    "   0.0012012012012012011,\n",
    "   0.0006075334143377885],\n",
    "  'brevity_penalty': 1.0,\n",
    "  'length_ratio': 1.5724838411819022,\n",
    "  'translation_length': 1703,\n",
    "  'reference_length': 1083},\n",
    " {'rouge1': np.float64(0.1541466945728513),\n",
    "  'rouge2': np.float64(0.017248572697572115),\n",
    "  'rougeL': np.float64(0.10011529596140455),\n",
    "  'rougeLsum': np.float64(0.10759896171220223)},\n",
    " {'precision': [0.8012092113494873,\n",
    "   0.8241617679595947,\n",
    "   0.689644455909729,\n",
    "   0.8287801742553711,\n",
    "   0.833304762840271,\n",
    "   0.828080415725708,\n",
    "   0.847261905670166,\n",
    "   0.8211007118225098,\n",
    "   0.8315057754516602,\n",
    "   0.8339003324508667,\n",
    "   0.0,\n",
    "   0.8351423144340515,\n",
    "   0.8233726620674133,\n",
    "   0.8133792877197266,\n",
    "   0.8384840488433838,\n",
    "   0.8493857383728027,\n",
    "   0.8207684755325317,\n",
    "   0.8209556341171265,\n",
    "   0.8152289986610413,\n",
    "   0.8355612754821777],\n",
    "  'recall': [0.8248466849327087,\n",
    "   0.8207997679710388,\n",
    "   0.7795955538749695,\n",
    "   0.8241584897041321,\n",
    "   0.812791109085083,\n",
    "   0.8288900852203369,\n",
    "   0.8190089464187622,\n",
    "   0.8341827988624573,\n",
    "   0.8611392378807068,\n",
    "   0.8294829726219177,\n",
    "   0.0,\n",
    "   0.8128516674041748,\n",
    "   0.8051705360412598,\n",
    "   0.787691593170166,\n",
    "   0.8530493974685669,\n",
    "   0.8260535597801208,\n",
    "   0.8206564784049988,\n",
    "   0.8531922698020935,\n",
    "   0.8612176179885864,\n",
    "   0.8429147005081177],\n",
    "  'f1': [0.812856137752533,\n",
    "   0.8224772810935974,\n",
    "   0.7318664789199829,\n",
    "   0.8264629244804382,\n",
    "   0.8229201436042786,\n",
    "   0.8284850716590881,\n",
    "   0.8328958749771118,\n",
    "   0.8275901079177856,\n",
    "   0.8460630178451538,\n",
    "   0.8316857814788818,\n",
    "   0.0,\n",
    "   0.8238462209701538,\n",
    "   0.8141698837280273,\n",
    "   0.8003293871879578,\n",
    "   0.8457040190696716,\n",
    "   0.8375571370124817,\n",
    "   0.8207125067710876,\n",
    "   0.8367636203765869,\n",
    "   0.8375924825668335,\n",
    "   0.8392218947410583],\n",
    "  'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.51.3)'},\n",
    " 0.7819599986076355)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ee9b203-3ad5-47b0-b5a2-9ed8c459f108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results ---\n",
      "Dataset: kateacuff\n",
      "Split: train\n",
      "BLEU: 0.0061\n",
      "ROUGE-L: 0.1001\n",
      "BERTScore F1: 0.7820\n"
     ]
    }
   ],
   "source": [
    "            print(\"\\n--- Evaluation Results ---\")\n",
    "            print(f\"Dataset: {dataset_name}\")\n",
    "            print(f\"Split: {train_or_test}\")\n",
    "            print(f\"BLEU: {bleu_score['bleu']:.4f}\")\n",
    "            print(f\"ROUGE-L: {rouge_score['rougeL']:.4f}\")\n",
    "            print(f\"BERTScore F1: {avg_bertscore_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e63a32a-06ec-4533-a265-2772c1f7442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list.append({\n",
    "    \"ModelName\": 'No-FineTuning',\n",
    "    \"dataset\": dataset_name,\n",
    "    \"split\": 'test',\n",
    "    \"BLEU\": bleu_score[\"bleu\"],\n",
    "    \"ROUGE-L\": rouge_score[\"rougeL\"],\n",
    "    \"BERTScore_F1\": avg_bertscore_f1\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02c3f3b-3717-4f3b-9bfd-8c69f6dbe6f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "unsloth_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
