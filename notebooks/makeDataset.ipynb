{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5347594c-81b8-45b1-a300-0ddd35fd9ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd584ca6-423e-48f0-8a02-c9d33666e336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_segments(segments):\n",
    "    for segment in segments:\n",
    "        print(segment['speaker'] + ': ' + segment['text'])\n",
    "        \n",
    "def clean_text(text):\n",
    "    \"\"\"Clean text by removing disfluencies and normalizing whitespace/punctuation.\"\"\"\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = re.sub(r'\\s([?.!,\"])', r'\\1', text)\n",
    "    return text\n",
    "\n",
    "def build_dialogue_dataset(segments, target_speaker='SPEAKER_06'):\n",
    "    \"\"\"\n",
    "    Build dataset with:\n",
    "    - context: prior dialogue (speaker-tagged when changing)\n",
    "    - response: one or more consecutive turns by target_speaker\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    context_parts = []\n",
    "    prev_speaker = None\n",
    "    i = 0\n",
    "\n",
    "    while i < len(segments):\n",
    "        segment = segments[i]\n",
    "        speaker = segment.get('speaker')\n",
    "        text = clean_text(segment.get('text', ''))\n",
    "\n",
    "        if not text:\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        if speaker == target_speaker:\n",
    "            # Collect all consecutive target_speaker turns\n",
    "            response_parts = [text]\n",
    "            i += 1\n",
    "            while i < len(segments) and segments[i]['speaker'] == target_speaker:\n",
    "                next_text = clean_text(segments[i]['text'])\n",
    "                if next_text:\n",
    "                    response_parts.append(next_text)\n",
    "                i += 1\n",
    "            if context_parts:\n",
    "                dataset.append({\n",
    "                    \"context\": ' \\n'.join(context_parts),\n",
    "                    \"response\": ' '.join(response_parts)\n",
    "                })\n",
    "            context_parts = []\n",
    "            prev_speaker = None  # reset after Alicia speaks\n",
    "        else:\n",
    "            if speaker != prev_speaker:\n",
    "                context_parts.append(f\"{speaker}: {text}\")\n",
    "            else:\n",
    "                context_parts.append(text)\n",
    "            prev_speaker = speaker\n",
    "            i += 1\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def count_words_in_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Counts total number of words in 'context' and 'response' fields of a dialogue dataset.\n",
    "    \n",
    "    Args:\n",
    "        dataset (list): List of dicts with 'context' and 'response' keys.\n",
    "\n",
    "    Returns:\n",
    "        dict: {'context_word_count': int, 'response_word_count': int}\n",
    "    \"\"\"\n",
    "    context_word_count = 0\n",
    "    response_word_count = 0\n",
    "\n",
    "    for entry in dataset:\n",
    "        context = entry.get('context', '')\n",
    "        response = entry.get('response', '')\n",
    "        context_word_count += len(context.split())\n",
    "        response_word_count += len(response.split())\n",
    "\n",
    "    return {\n",
    "        'context_word_count': context_word_count,\n",
    "        'response_word_count': response_word_count\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb37b6f6-e812-4f1e-94ea-f9d382d96887",
   "metadata": {},
   "source": [
    "### Jon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1f3d8e93-3e08-44d0-9643-ec24cb6f0459",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'transcripts/jon.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m jon_segments \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtranscripts/jon.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m jon_dataset \u001b[38;5;241m=\u001b[39m build_dialogue_dataset(jon_segments, target_speaker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSPEAKER_06\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m jon_word_counts \u001b[38;5;241m=\u001b[39m count_words_in_dataset(jon_dataset)\n",
      "File \u001b[0;32m/nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'transcripts/jon.npy'"
     ]
    }
   ],
   "source": [
    "jon_segments = np.load('transcripts/jon.npy', allow_pickle=True)\n",
    "jon_dataset = build_dialogue_dataset(jon_segments, target_speaker='SPEAKER_06')\n",
    "\n",
    "jon_word_counts = count_words_in_dataset(jon_dataset)\n",
    "print(jon_word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c70656f-0aa4-4436-bdd6-648387b31834",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Maria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "644cc0ea-94c4-48d3-bea8-41a90092e350",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'transcripts/maria.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m maria_segments \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtranscripts/maria.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m maria_dataset \u001b[38;5;241m=\u001b[39m build_dialogue_dataset(maria_segments, target_speaker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSPEAKER_06\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m maria_word_counts \u001b[38;5;241m=\u001b[39m count_words_in_dataset(maria_dataset)\n",
      "File \u001b[0;32m/nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'transcripts/maria.npy'"
     ]
    }
   ],
   "source": [
    "maria_segments = np.load('transcripts/maria.npy', allow_pickle=True)\n",
    "maria_dataset = build_dialogue_dataset(maria_segments, target_speaker='SPEAKER_06')\n",
    "np.save('datasets/maria_dataset.npy', maria_dataset)\n",
    "\n",
    "maria_word_counts = count_words_in_dataset(maria_dataset)\n",
    "print(maria_word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a591aa-054c-4d51-8a00-9b8b75210055",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Laurie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b0609e2d-1b83-4868-86e9-ae13dbd8c97a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_word_count': 730, 'response_word_count': 2209}\n"
     ]
    }
   ],
   "source": [
    "laurie_segments = np.load('transcripts/laurie.npy', allow_pickle=True)\n",
    "laurie_dataset = build_dialogue_dataset(laurie_segments, target_speaker='SPEAKER_03')\n",
    "np.save('datasets/laurie_dataset.npy', laurie_dataset)\n",
    "\n",
    "# print_segments(laurie_segments)\n",
    "# Laurie = SPEAKER_03\n",
    "\n",
    "laurie_word_counts = count_words_in_dataset(laurie_dataset)\n",
    "print(laurie_word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a7c398-903f-4afb-9149-fd20ea897ddf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Alicia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6e7a8ac1-c403-4427-ab83-22e93f05aea8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_word_count': 762, 'response_word_count': 1705}\n"
     ]
    }
   ],
   "source": [
    "alicia_segments = np.load('transcripts/alicia.npy', allow_pickle=True)\n",
    "alicia_dataset = build_dialogue_dataset(alicia_segments, target_speaker='SPEAKER_06')\n",
    "np.save('datasets/alicia_dataset.npy', alicia_dataset)\n",
    "\n",
    "# print_segments(alicia_segments)\n",
    "# Laurie = SPEAKER_06\n",
    "alicia_word_counts = count_words_in_dataset(alicia_dataset)\n",
    "print(alicia_word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ae156d-173c-43f9-b5a3-2dbad0ce1c4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Stacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e6558f8-1a5b-499b-b5b3-c6967fa91100",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'transcripts/stacy.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stacy_segments \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtranscripts/stacy.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m stacy_dataset \u001b[38;5;241m=\u001b[39m build_dialogue_dataset(stacy_segments, target_speaker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSPEAKER_06\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m stacy_word_counts \u001b[38;5;241m=\u001b[39m count_words_in_dataset(stacy_dataset)\n",
      "File \u001b[0;32m/nas/longleaf/rhel8/apps/anaconda/2023.03.ood/lib/python3.10/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'transcripts/stacy.npy'"
     ]
    }
   ],
   "source": [
    "stacy_segments = np.load('transcripts/stacy.npy', allow_pickle=True)\n",
    "stacy_dataset = build_dialogue_dataset(stacy_segments, target_speaker='SPEAKER_06')\n",
    "np.save('datasets/stacy_dataset.npy', stacy_dataset)\n",
    "\n",
    "stacy_word_counts = count_words_in_dataset(stacy_dataset)\n",
    "print(stacy_word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fa32ca-a053-44fb-a120-706f3de9de90",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Jennifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b2881da-643c-471f-bc62-6b1bb46c7b3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_word_count': 941, 'response_word_count': 3157}\n"
     ]
    }
   ],
   "source": [
    "jennifer_segments = np.load('transcripts/jennifer.npy', allow_pickle=True)\n",
    "jennifer_dataset = build_dialogue_dataset(jennifer_segments, target_speaker='SPEAKER_01')\n",
    "np.save('datasets/jennifer_dataset.npy', jennifer_dataset)\n",
    "\n",
    "# print_segments(jennifer_segments)\n",
    "# jennifer = SPEAKER_01\n",
    "\n",
    "jennifer_word_counts = count_words_in_dataset(jennifer_dataset)\n",
    "print(jennifer_word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f515cd1-4543-47a4-bba7-21114dcdbdfd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Richard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2bd5b4b5-48c8-43d8-bee5-e79e2a29736a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_word_count': 3885, 'response_word_count': 172}\n"
     ]
    }
   ],
   "source": [
    "richard_segments = np.load('transcripts/richard.npy', allow_pickle=True)\n",
    "richard_dataset = build_dialogue_dataset(richard_segments, target_speaker='SPEAKER_06')\n",
    "np.save('datasets/richard_dataset.npy', richard_dataset)\n",
    "\n",
    "# print_segments(richard_segments)\n",
    "# richardr = SPEAKER_01\n",
    "\n",
    "\n",
    "richard_word_counts = count_words_in_dataset(richard_dataset)\n",
    "print(richard_word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b2499c17-6dea-426a-9f62-1ffe78437442",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPEAKER_06:  Okay, we're here with the school board president Jennifer Smith, and she's running for reelection.\n",
      "SPEAKER_06: Thanks for being here, Jennifer, you want to just talk about your, your, your reason for running and your experience on after your first term.\n",
      "SPEAKER_01:  Right, okay, thank you.\n",
      "SPEAKER_01: Thank you for having me.\n",
      "SPEAKER_01: Um, so I, um.\n",
      "SPEAKER_01: I've been in the school district for over 15.\n",
      "SPEAKER_01: I have a child who's 20, so they started in preschool at and I couldn't be great more grateful to have a preschool program that runs through the district because.\n",
      "SPEAKER_01: And it really was, it's a wonderful program and not many school districts had a public preschool program at the time.\n",
      "SPEAKER_01: Um, I.\n",
      "SPEAKER_01:  And then I started when I started to learn about education in California and how funding worked in the district, I really got very passionate about public schools and public school funding and and wanting to participate and make it better.\n",
      "SPEAKER_01: So, through those many years, I volunteered a lot and with a lot of mentors in the district of people, you all, you all know.\n",
      "SPEAKER_01:  And so in 2020, when I had a senior in high school and an incoming senior and incoming freshman, and I felt like I had some background and understanding, and as I have learned, you can never stop learning because I thought I knew a lot and then got into this position and realized\n",
      "SPEAKER_01:  There's so much more to learn.\n",
      "SPEAKER_01: So I just felt like it was a really important step.\n",
      "SPEAKER_01: I wanted to see the district continue in the direction that it was going in.\n",
      "SPEAKER_01: I really believed in the equity issues that were happening and all the and the programs that we're putting in place and being able to reach kids.\n",
      "SPEAKER_01: I thought it was extraordinary.\n",
      "SPEAKER_01: I thought the district was extraordinary.\n",
      "SPEAKER_01: And it's not just trying to maintain, but really improve and dig down and really\n",
      "SPEAKER_01:  people who really cared.\n",
      "SPEAKER_01: So I got myself involved and I've just been learning ever since getting on the board.\n",
      "SPEAKER_01: It's really been interesting and satisfying to be able to see things move ahead, but also so much more to do.\n",
      "SPEAKER_06:  Well, let's talk about some of that.\n",
      "SPEAKER_06: You mentioned in your questionnaire that you thought environmental justice issues and sustainability were important and kind of neglected on our questions.\n",
      "SPEAKER_06: So I'm interested to just give you the chance to speak about that.\n",
      "SPEAKER_06: I mean, I think we basically know about the sustainability goals of the school district.\n",
      "SPEAKER_06: You can talk about that too, but I'm really interested in the environmental justice aspect of that.\n",
      "SPEAKER_06: Where do you see\n",
      "SPEAKER_06:  there to be room to create that kind of justice in the district?\n",
      "SPEAKER_01: Well, I think it's in its infancy, because while our kids and our staff and everyone in the district is interested in creating a future environment that will sustain us, and that responsibility that we take on, and of\n",
      "SPEAKER_01:  Of course, it's always a little frustrating trying to figure out where to fit all that in, and also the main mission of educating kids.\n",
      "SPEAKER_01: But I think the environmental justice thing is really in its infancy in our world and our understanding of how it affects the kids in our district.\n",
      "SPEAKER_01: So I really, so while I would like to tell you I have a plan, I don't.\n",
      "SPEAKER_01:  But I think that it is something really, you know, worth exploring and figuring out what the pieces are and where it enters our world from the kids and the staff that come from, you know, from all over LA and what they're dealing with all over LA.\n",
      "SPEAKER_01: And so I just think it's, I think it's something to look, I think it's something to look into and take into account when we're making policy and when we're creating programs.\n",
      "SPEAKER_06:  Great.\n",
      "SPEAKER_06: Okay.\n",
      "SPEAKER_06: Let's go to Isabel.\n",
      "SPEAKER_02: Hi, Jennifer.\n",
      "SPEAKER_02: So, I looked over your priorities for the district and one of them was engagement of our students in the curriculum.\n",
      "SPEAKER_02: So, I was wondering if you could expand on that and tell us why that's important to you and what it means.\n",
      "SPEAKER_01:  Well, I think, I mean, I think we all know that we've, you know, everybody's gone to school and not felt that connection not felt that understanding not felt at why things are relative to them.\n",
      "SPEAKER_01: And I think that trying to contract continuing and trying to find those\n",
      "SPEAKER_01:  points of connection with kids and figuring out how to teach them what's in the curriculum.\n",
      "SPEAKER_01: Obviously, that's something that is also state-mandated.\n",
      "SPEAKER_01: Why it relates to them, how it connects to them, what they can see their future in.\n",
      "SPEAKER_01: And so we've started doing a lot of project-based learning in elementary schools and moving it outwards, right?\n",
      "SPEAKER_01: So just sort of\n",
      "SPEAKER_01:  Training teachers more and more every year.\n",
      "SPEAKER_01: I mean, it takes a lot and it takes a lot of resources to do that.\n",
      "SPEAKER_01: And it takes a lot of commitment to make sure that teachers have the resources they need in the support that they need to be able to actually do that in the classrooms every day with their kids.\n",
      "SPEAKER_01: So I think.\n",
      "SPEAKER_01:  uh, doing, um, more of that.\n",
      "SPEAKER_01: I know that, I mean, that, that is the plan in the district.\n",
      "SPEAKER_01: That's Dr. Shelton's vision.\n",
      "SPEAKER_01: Um, so really, uh, and then in the high school, creating those academies, the, um, physiology academy has, is really launching next year.\n",
      "SPEAKER_01: The government and law is really launching next year, but for them to be able, for kids to be able to make some choices and own\n",
      "SPEAKER_01:  own their own educational system and make sure that they see their future.\n",
      "SPEAKER_01: They don't have to see everything, but to understand their interests.\n",
      "SPEAKER_01: Because I'm a big believer in the fact that they don't have to know, kids don't have to know in high school what they want to do.\n",
      "SPEAKER_01: I think it's a little too much pressure that seems to be in our educational system these days.\n",
      "SPEAKER_01: But also they need to see the opportunities that might be in front of them.\n",
      "SPEAKER_01:  Okay, thanks, sure.\n",
      "SPEAKER_06: All right, let's go to Sam.\n",
      "SPEAKER_07: Hey Jennifer, to your mental health focus, how has, I guess like almost 18 months ago now when governors came down to Santa Monica, what was that experience like and what did you learn from it and take away from it?\n",
      "SPEAKER_01:  Well, I learned that I think that we're a pretty innovative district.\n",
      "SPEAKER_01: I think they wanted to come and see what we were doing.\n",
      "SPEAKER_01: And that was pretty, pretty great.\n",
      "SPEAKER_01: And then the county at Laco, who created the community schools, and we have Margaret's Place.\n",
      "SPEAKER_01: But I learned is that we have to cobble together mental health, which doesn't always thrill me.\n",
      "SPEAKER_01:  I, I, and it's and to be perfectly honest now with the governor's budget, I'm not sure how stable it is.\n",
      "SPEAKER_01: So we'll see what, you know, what we can keep pulled, keep pulling together, but we always seem to be reaching out to new things and new places and new resources.\n",
      "SPEAKER_01: So I hope we can still do that.\n",
      "SPEAKER_01: If we are.\n",
      "SPEAKER_01:  if we don't have the sustainability that we have for the programs we have now.\n",
      "SPEAKER_01: But I also hope that what that showed was that there is some sort of commitment from a state and state government that wants to de-stigmatize mental health and make sure that it's part of our kids' world because they really need it.\n",
      "SPEAKER_06: Okay, Lynn.\n",
      "SPEAKER_04:  Hi, Jennifer, I have two questions that should be easily answered with a short answer.\n",
      "SPEAKER_04: One is, has the district received any funding from the Bipartisan Safe Community Act to help fund more training and hiring of mental health professionals?\n",
      "SPEAKER_04: You were just speaking of that.\n",
      "SPEAKER_04:  It, it may be from just under I think it might be just underprivileged schools, but I was just wondering if you received any.\n",
      "SPEAKER_01:  I am unaware of that being a source.\n",
      "SPEAKER_01: It doesn't mean it doesn't exist, but I am unaware of that being a source for our mental health programs.\n",
      "SPEAKER_01: OK, my other question is, do you know if the district has begun to discuss the implementation of Rick Sabour safe and supportive school act passed last year?\n",
      "SPEAKER_04: It has to do with.\n",
      "SPEAKER_04:  an annual one-hour online LGBTQ cultural competency training course required of all teachers, but it doesn't begin until 2025-26 school year, so I'm not sure.\n",
      "SPEAKER_04: I'm just wondering if there's discussion about it yet.\n",
      "SPEAKER_01: Right.\n",
      "SPEAKER_01: Well, we might have some programs that align with that already because I wish I had my badge around my neck.\n",
      "SPEAKER_01: We have a Safe Schools program that teachers log into.\n",
      "SPEAKER_01: It's a\n",
      "SPEAKER_01:  It's a digital program where they go through that aligns with that.\n",
      "SPEAKER_01: So I don't know.\n",
      "SPEAKER_01: And I know that we have in place, we've had in place teacher training about the Safe Schools Act.\n",
      "SPEAKER_01: So I would have to look more deeply into it, but I could do that.\n",
      "SPEAKER_01: And I'm sure that we would be enthusiastic.\n",
      "SPEAKER_01: And I hope there's funding for it.\n",
      "SPEAKER_04:  Thank you.\n",
      "SPEAKER_06: OK, let's go to Natalia.\n",
      "SPEAKER_00: Hi, Jen, nice to see you.\n",
      "SPEAKER_00: So I wanted to build a little bit on Sam's question about your response to supporting the mental health needs of culturally diverse learners.\n",
      "SPEAKER_00: Something I found really interesting in your answer was that you noted\n",
      "SPEAKER_00:  widening the use of restorative justice practices and continuing to expand social justice standards.\n",
      "SPEAKER_00: I don't have kids in the school district, so I don't know.\n",
      "SPEAKER_00: And I was just curious what restorative justice practices are currently being used in the school district and how would you like to see those expanded?\n",
      "SPEAKER_01:  Well, so, I mean, as a lot of things like project-based learning and things like that, it's all about the people and staff in our schools that provide the programs like restorative justice to be implemented.\n",
      "SPEAKER_01: And so while we have a bunch of schools that have all of their, so there's three levels to restorative justice.\n",
      "SPEAKER_01: There's level one, which is a community-based scenario, level two, which is,\n",
      "SPEAKER_01:  which is, so sorry, I actually just went to level two training this year.\n",
      "SPEAKER_01: It's more, so level one is community-based, level three is conflict resolution, and level two is doing community groups and information and more\n",
      "SPEAKER_01:  So sorry, the word is escaping me because they have very specific definitions of things.\n",
      "SPEAKER_01: So it's a layered approach, right?\n",
      "SPEAKER_01: So it's not just when people think of restorative justice, it's not just about coming together and finding when problems exist.\n",
      "SPEAKER_01: So we have a layer of training.\n",
      "SPEAKER_01: Everyone in the district is trained in\n",
      "SPEAKER_01:  restorative justice in level one and so to keep and so that takes\n",
      "SPEAKER_01:  time and money to have teachers come in and do the training.\n",
      "SPEAKER_01: And then it also takes pushing into the classrooms and into the school systems as well.\n",
      "SPEAKER_01: So there is so widening it, meaning having the actual training that exists for all teachers in the entire district to be competent at what restorative justice means for kids in a classroom and how to create community to avoid conflict.\n",
      "SPEAKER_01: Conflict resolution.\n",
      "SPEAKER_01: Sorry, that was\n",
      "SPEAKER_01:  Sorry, that was level three, I think.\n",
      "SPEAKER_01: So broadening the restorative justice practice.\n",
      "SPEAKER_01: And then the social justice standards is definitely more about embedding it in the curriculum and making sure that all of our kids see themselves in their education and see themselves\n",
      "SPEAKER_01:  in what they're learning and understand it in the world related to them and understand the world, the diversity that exists in the world so they can live in sort of peace in it.\n",
      "SPEAKER_02: Keith.\n",
      "SPEAKER_03: Get off mute here.\n",
      "SPEAKER_03: Hi, Jan.\n",
      "SPEAKER_03: How are you?\n",
      "SPEAKER_03: Thanks.\n",
      "SPEAKER_04: Good.\n",
      "unknown: OK.\n",
      "SPEAKER_03:  Great, good to see you.\n",
      "SPEAKER_03: Hey, so as you were describing with the positive things that the district is doing and expanding PBL and so that kids can kind of find themselves within their own kind of educational journey and pathways, I think one of the things too with students' concern and finding themselves is kind of trying to see themselves.\n",
      "SPEAKER_03:  and see themselves within teachers and see themselves within administrators.\n",
      "SPEAKER_03: And I know that from my time on the board, the big question was, well, how do we find talent of teachers and of administrators that are diverse?\n",
      "SPEAKER_03: So can you kind of describe maybe some of the new things over the past couple of years that the district has done to really try and bring more diversity with teachers and administrators?\n",
      "SPEAKER_01:  Um, yes, so well, I, it's funny that you, this is the question I was thinking about that today, but I was thinking about, well, when we, when Dr came and being the English language learner that he was and his understanding of how to reach kids in that way, and then bringing staff in to.\n",
      "SPEAKER_01:  To widen the, the ability for, I mean, what has happened in the district for English language learners has been extraordinary in the last 5 to 6, 6, 7 years because of Dr. Drati.\n",
      "SPEAKER_01: So, it absolutely is so apparent to me that we have to have.\n",
      "SPEAKER_01:  a deep understanding of what kids need and some people and have a broad diversity of staff to know and be able to bring those things in.\n",
      "SPEAKER_01: So what has the district, I know, I just, there's, you know, it's a tough hiring world.\n",
      "SPEAKER_01: It really, it's really extraordinary.\n",
      "SPEAKER_01: And I know that our staff and Dr. Kelly and the Human Resource Department has been doubling down on their efforts of\n",
      "SPEAKER_01:  Going to they just came back.\n",
      "SPEAKER_01: There was a huge job fair at Laco.\n",
      "SPEAKER_01: I don't know that I didn't remember in the past that the district had.\n",
      "SPEAKER_01: Had done a lot of outreach in that way and so what I've seen in the last few years, just being around is that that those things are much more in play that they're finding more and and reaching out more and even.\n",
      "SPEAKER_01:  Um, even things, especially in the special education department, because that is where, you know, we're in a, you know, a little bit of, uh, we're behind in hiring and making sure that there's a special education staff and, um, it is robust and that, I mean, you have to be a.\n",
      "SPEAKER_01:  you have to be a very special person to fill that role and to be that teacher and to be able to maintain and sustain.\n",
      "SPEAKER_01: I think the district is just doing more and more outreach to be able to hire in those capacities and where the need exists.\n",
      "SPEAKER_03: Great.\n",
      "SPEAKER_03: Thanks again.\n",
      "SPEAKER_03: Thanks for your leadership.\n",
      "SPEAKER_06: Thanks.\n",
      "SPEAKER_06: Let's go to Mike.\n",
      "SPEAKER_05:  Hey, Jen, so 2 years ago, the voters of Santa Monica passed the 2nd measure GS.\n",
      "SPEAKER_05: Um, to raise money for our schools and for affordable housing programs.\n",
      "SPEAKER_05: And, uh, after an unsuccessful effort to defeat it at the ballot box after an unsuccessful legal challenge.\n",
      "SPEAKER_05: We now have Cypress equity in Madison capital funding.\n",
      "SPEAKER_05: A.\n",
      "SPEAKER_05:  effort to put on the ballot a measure that would exempt all multi-family housing, new and existing, so that, for example, Douglas Emma could sell the shores and not contribute a dime to our affordable housing or to our schools.\n",
      "SPEAKER_05: So can you tell us what your position is on that and what, if it does make it to the ballot, you would be doing to try and get the voters of Santa Monica to adopt your position?\n",
      "SPEAKER_01:  Well, it's astounding to me.\n",
      "SPEAKER_01: I can't believe that this is happening for, like you said, the third time trying to defeat something that the voters passed.\n",
      "SPEAKER_01: I find it just reprehensible.\n",
      "SPEAKER_01: I actually have been\n",
      "SPEAKER_01:  just informing our partners, our community partners, our parent partners, of what has been happening.\n",
      "SPEAKER_01: And if that actually gets on the ballot, I would absolutely\n",
      "SPEAKER_01:  think I would like to take a position to defeat that.\n",
      "SPEAKER_01: I don't know what my other board members would do, but that would absolutely be.\n",
      "SPEAKER_01: And I would, in my, you know, I mean, I've been deeply rooted in PTA and I would like them to understand the risk that comes now with what that would mean to our schools and to our community.\n",
      "SPEAKER_01: And so I just find it remarkable that,\n",
      "SPEAKER_01:  And I've been at the supermarkets, I've been hearing the lies that have been told about what the measure means.\n",
      "SPEAKER_01: And I don't understand why anyone would, any voter in Santa Monica would think that that is going to create a better, would be, why they as a voter would\n",
      "SPEAKER_01:  be in favor of that unless they're lied to.\n",
      "SPEAKER_01: So I can't quite figure it out, but so I guess I usually take things one step at a time and I'm practical.\n",
      "SPEAKER_01: So I haven't like thought all the way down the road, but I truly hope that it doesn't actually make the ballot.\n",
      "SPEAKER_06: Great.\n",
      "SPEAKER_06: Thank you.\n",
      "SPEAKER_06: Let's go to Sam.\n",
      "SPEAKER_07:  So you were speaking a little bit about retaining staff in your question, just to expand upon that.\n",
      "SPEAKER_07: Have you found it an issue for teachers to move to private schools for better pay?\n",
      "SPEAKER_07: And if so, how have you been able to\n",
      "SPEAKER_07:  retain staff for this issue and a multitude of other issues.\n",
      "SPEAKER_01:  As far as I, my knowledge is, which, you know, I don't have all the facts, but I generally public school teachers make more than private school teachers.\n",
      "SPEAKER_01: I understand that there's, there's advantages to working in private schools that some teachers find, you know, can, you know, that they in public school, I mean, it's a big government, you know, red tape kind of world.\n",
      "SPEAKER_01: So I'm sure that there are advantages that teachers, you know, that have,\n",
      "SPEAKER_01:  have teachers pulled into a private school world.\n",
      "SPEAKER_01: I do know that we have, well, you know, in terms, so as a basic aid district, we don't fund, we don't have, we don't get money from the state in the COLA\n",
      "SPEAKER_01:  Uh, formula to, um, to basically lift our teachers up as a basic 8 district.\n",
      "SPEAKER_01: We have to do that through our budget and we have to create a, um, create a pathway.\n",
      "SPEAKER_01: So that we know that our teachers are compensated in a way that is competitive.\n",
      "SPEAKER_01: So we've just finished negotiations and I believe both.\n",
      "SPEAKER_01:  CTA and SEIU have ratified contracts that haven't been approved yet through the board, but are coming and we are on par.\n",
      "SPEAKER_01: I know that with a lot of the other California state CTA unions and SEIU and salaries, we so and there are special circumstances in each places like, I mean, especially with keeping up with the rising, which.\n",
      "SPEAKER_01:  Minimum wage rates for for classified staff is, you know, something that we have to keep on top of and make sure that we're aligning with and that.\n",
      "SPEAKER_01: And, you know, I mean, and also, I mean, like, I just, I mean, everybody wants to make a living wage and I, and that's what they should be making and.\n",
      "SPEAKER_01:  budgeting and using our resources in that way.\n",
      "SPEAKER_01: So we have the staff that we need and they have the life so that they can come and work for us is really important.\n",
      "SPEAKER_01: So I think that we just, I think that has to happen in keeping up with being able to support staff and what it costs to educate kids.\n",
      "SPEAKER_01: And the fact is, is that some of the people live in Santa Monica, some teachers and staff have lived here for a long time.\n",
      "SPEAKER_01:  But some commute from very far places.\n",
      "SPEAKER_01: And housing is really important to figure out how we can staff people, good people, the right people that we need in our schools.\n",
      "SPEAKER_01: So I don't know.\n",
      "SPEAKER_01: I think that's why I really have enjoyed, in terms of the collaborativeness that exists a lot in this city, to figure out that.\n",
      "SPEAKER_01: And especially that housing piece is really important.\n",
      "SPEAKER_06:  Okay, Isabel.\n",
      "SPEAKER_02: Yeah, hi again.\n",
      "SPEAKER_02: So you listed the budget as your top priority on the school board, so I'm wondering, you know, in your first term, what did you do to help with that?\n",
      "SPEAKER_02: And going forward, what do you think is the biggest challenge and how would you like to address it?\n",
      "SPEAKER_02:  Well, I think that there's always challenge.\n",
      "SPEAKER_01: I mean, each time we go through the budget, it just astounds me how the state funds education and funds our district in particular.\n",
      "SPEAKER_01: It's a little different than most of the districts.\n",
      "SPEAKER_01: And then so we have been talking about for a little while, and I think it's very important\n",
      "SPEAKER_01:  That we come to an agreement with our partners in the district, but we also understand the risks, inherent risks of basic aid.\n",
      "SPEAKER_01: And I think that we haven't so I am.\n",
      "SPEAKER_01:  I am hoping that in the next six months that we can figure out where we can all be and make sure that the district can, you know, remain in a strong fiscal position.\n",
      "SPEAKER_01: So that is, I mean, I think reserve policy is a really important one.\n",
      "SPEAKER_01: And I think we can get there with everybody being on the same page.\n",
      "SPEAKER_01: I also think, you know, for a long time, I've understood what, for what I've kind of learned is that a long time, the way negotiations and the way\n",
      "SPEAKER_01:  the district spends money is always seems to be reactive, and I'd like to see it much more proactive and much more futuristic looking and much more, you know, you can't, I mean, you can't predict everything, but you can predict some things like there's going to be a little inflation, you know, like there's going to be, there are going to be raises coming, there are going to be higher costs of things.\n",
      "SPEAKER_01: And so if we can\n",
      "SPEAKER_01:  plan more about that kind of stuff instead of just planning the budget for the money that is coming in.\n",
      "SPEAKER_01: I just think that we would have a much better perspective down the road and we can plan better for things.\n",
      "SPEAKER_01: I think school funding is very fraught\n",
      "SPEAKER_01:  And so I'd like to feel a little more secure.\n",
      "SPEAKER_01: I think that I just, I would just like the district to be a little more secure in its futuristic planning.\n",
      "SPEAKER_01: And if we do, you know, when we do things like academies, and we do things like, you know,\n",
      "SPEAKER_01:  that we, because we want to keep growing in our educational plan, how we plan to budget it and how we plan to have the resources for it and how we, and I do have to say Dr. Shelton right now is going through all his priorities and budgeting is one of them and making sure that we are using the money that we have in the best possible ways.\n",
      "SPEAKER_01: So, and figuring out what's not necessary, figuring out\n",
      "SPEAKER_01:  what has been, you know, what might be in the past that we don't need anymore, figuring out what looks, what futuristic things are, you know, are in our, what we, what we'll need in the future.\n",
      "SPEAKER_01: So I don't, did that quite, sometimes I get lost.\n",
      "SPEAKER_01: I'm sorry in my own.\n",
      "SPEAKER_02: I think so.\n",
      "SPEAKER_02: No, I got the gist of that.\n",
      "SPEAKER_06:  Okay, let's see.\n",
      "SPEAKER_06: Any last questions?\n",
      "SPEAKER_06: If not, okay.\n",
      "SPEAKER_06: Thanks, Jennifer.\n",
      "SPEAKER_06: Thanks for being here.\n",
      "SPEAKER_06: If you want to have any closing statement, you're welcome to.\n",
      "SPEAKER_01:  No, I would just I would just say thank you for having me.\n",
      "SPEAKER_01: And I would just say so it was I it was I liked the questionnaire.\n",
      "SPEAKER_01: I thought it was there were so many good questions and I would just caveat that with I have a graduating senior.\n",
      "SPEAKER_01: I'm getting ready for grad night and being and doing the board stuff.\n",
      "SPEAKER_01: And then this this caught me a little earlier than I thought.\n",
      "SPEAKER_01: And so I haven't gotten in full swing, but I really appreciate the questions and I hope I got to\n",
      "SPEAKER_01:  give you at least a little of what was on my mind with my answers.\n",
      "SPEAKER_01: So thank you.\n",
      "SPEAKER_01: No, definitely.\n",
      "SPEAKER_06: The questionnaire was great.\n",
      "SPEAKER_06: Today we got a lot more and we'll see you on Wednesday for the debate event.\n",
      "SPEAKER_01: Yes, I'll be there.\n",
      "SPEAKER_01: Thank you so much.\n",
      "SPEAKER_01: Thank you all for all you do.\n",
      "SPEAKER_06: Thank you.\n",
      "SPEAKER_01: Take care.\n"
     ]
    }
   ],
   "source": [
    "print_segments(richard_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223e4ec0-0fd0-423d-8d94-18ca211d5ae4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Meta-df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7ce8b3ad-e0c2-4822-947b-c0891decfa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'alicia': alicia_dataset,\n",
    "    'jennifer': jennifer_dataset,\n",
    "    'richard': richard_dataset,\n",
    "    #'stacy': stacy_dataset,\n",
    "    'laurie': laurie_dataset,\n",
    "    #'maria': maria_dataset,\n",
    "    #'jon': jon_dataset\n",
    "}\n",
    "\n",
    "word_counts = {}\n",
    "for name, dataset in datasets.items():\n",
    "    word_counts[name] = count_words_in_dataset(dataset)\n",
    "\n",
    "# Build list of metadata dicts for DataFrame\n",
    "meta_info = []\n",
    "for name, dataset in datasets.items():\n",
    "    counts = word_counts[name]\n",
    "    total_words = counts['context_word_count'] + counts['response_word_count']\n",
    "    avg_words = total_words / len(dataset) if len(dataset) > 0 else 0\n",
    "    meta_info.append({\n",
    "        'name': name,\n",
    "        'num_examples': len(dataset),\n",
    "        'context_word_count': counts['context_word_count'],\n",
    "        'response_word_count': counts['response_word_count'],\n",
    "        'total_words': total_words,\n",
    "        'avg_words_per_example': avg_words\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(meta_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a91660a6-ebc0-424f-a022-3f73beb30ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6159caa2-1209-4b09-9d74-6cc489166c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c4af3f-48e7-44dc-a1d6-6c78577f37cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
