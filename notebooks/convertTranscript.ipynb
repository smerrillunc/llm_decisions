{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "958b686f-6170-4fd6-b1a2-f58d48d5a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import difflib\n",
    "import textwrap\n",
    "\n",
    "def convert_transcript_to_finetune_data(\n",
    "    filename,\n",
    "    target_speaker,\n",
    "    match_threshold=0.8,\n",
    "    max_tokens=200,\n",
    "    max_context_utterances=5\n",
    "):\n",
    "    def split_long_response(response_text, max_tokens):\n",
    "        # Approximate 1 token â‰ˆ 5 characters\n",
    "        chunks = textwrap.wrap(response_text, width=max_tokens * 5)\n",
    "        return chunks\n",
    "\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    speaker_map = {}\n",
    "    speaker_id = 1\n",
    "    dialogue = []\n",
    "    known_speakers = set()\n",
    "\n",
    "    # Step 1: Parse lines and normalize speakers\n",
    "    for line in lines:\n",
    "        match = re.match(r\"\\[\\d{2}:\\d{2}:\\d{2} --> \\d{2}:\\d{2}:\\d{2}\\] (.*?):\\s+(.*)\", line)\n",
    "        if not match:\n",
    "            continue\n",
    "        speaker, text = match.groups()\n",
    "        speaker = speaker.strip().rstrip(':')\n",
    "        text = text.strip()\n",
    "\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        known_speakers.add(speaker)\n",
    "        is_target = bool(difflib.get_close_matches(speaker, [target_speaker], n=1, cutoff=match_threshold))\n",
    "        normalized_speaker = target_speaker if is_target else speaker_map.setdefault(\n",
    "            speaker, f\"Speaker_{speaker_id}\"\n",
    "        )\n",
    "\n",
    "        if not is_target and speaker not in speaker_map:\n",
    "            speaker_id += 1\n",
    "\n",
    "        dialogue.append((normalized_speaker, text))\n",
    "\n",
    "    # Step 2: Build fine-tuning examples\n",
    "    examples = []\n",
    "    context = []\n",
    "    buffer = []\n",
    "\n",
    "    for i, (speaker, text) in enumerate(dialogue):\n",
    "        if speaker == target_speaker:\n",
    "            buffer.append(text)\n",
    "            next_speaker = dialogue[i + 1][0] if i + 1 < len(dialogue) else None\n",
    "            if next_speaker != target_speaker:\n",
    "                full_response = \" \".join(buffer)\n",
    "                response_chunks = split_long_response(full_response, max_tokens)\n",
    "\n",
    "                trimmed_context = context[-max_context_utterances:]\n",
    "\n",
    "                for chunk in response_chunks:\n",
    "                    if trimmed_context:\n",
    "                        examples.append({\n",
    "                            \"messages\": [\n",
    "                                {\"role\": \"user\", \"content\": \"\\n\".join(trimmed_context)},\n",
    "                                {\"role\": \"assistant\", \"content\": chunk}\n",
    "                            ]\n",
    "                        })\n",
    "\n",
    "                context.append(f\"{speaker}: {full_response}\")\n",
    "                buffer = []\n",
    "        else:\n",
    "            context.append(f\"{speaker}: {text}\")\n",
    "\n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d58ae3dc-49b8-46c6-8d30-ea08af23a341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 training samples written to 'output.jsonl'\n"
     ]
    }
   ],
   "source": [
    "target_speaker = \"Michael Leichlit\"\n",
    "data = convert_transcript_to_finetune_data('test.txt', target_speaker)\n",
    "\n",
    "# Print or export the result\n",
    "with open('output.jsonl', 'w', encoding='utf-8') as f_out:\n",
    "    for item in data:\n",
    "        f_out.write(json.dumps(item) + '\\n')\n",
    "\n",
    "print(f\"{len(data)} training samples written to 'output.jsonl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e4a719e3-9f8f-4570-94d6-cbe9c64f1471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': \"Michael Leichlit: And I just March 8th. My name is Mike Whitwider. And I serve as the superintendent of the Harvard Unified Union School District. I am calling this meeting to order at 601. This is an organizational meeting following our town hall meetings of 2024. So I am calling to order the newly seated Harvard Unified Union School Board for the district. In attendance on Zoom, we have 12 board members. We have no one absent and we have two vacant seats from the town of Waterbury. And just so everyone knows earlier today, I was in contact with the town clerk for Waterbury. There were right in candidates for those two seats, but there was no one who attained the number of 30. So that will be an open, two open seats that we will advertise beginning on Monday. There's a whole process in our manual that we follow regarding the appointment of board members. They first have to we advertise it. The Waterbury Select Board will interview and make recommendations to this school board and enter Vermont school code. This board is the one who makes the official appointment. So first before we start, I'd like to ask each member to introduce themselves and I would ask that you share your name. The town you serve and if you previously served on the board and when you were elected as well. That's a lot of information. So your name, your town. If you previously served on the board and if we did when how long you go on the board. So I don't know if this is the first time I've done a full zoom board meeting in a very long time. I think probably since I was at another school district. So I'm just going to go on my street and alcohol names as I see them from my left to right. So I'm going to stop start with Bobby rude and just go forget to unmute yourself.\\nSpeaker_1: I'm Bobby rude from weights field.\\nSpeaker_1: So I'm representing the town of weights field on the board.\\nSpeaker_1: And I've been on the board two years. This is entering my third year.\\nSpeaker_1: Thanks, Bobby. And next we'll go to Cindy sending.\"},\n",
       "  {'role': 'assistant',\n",
       "   'content': \"Hi, I'm Cindy sending and I'm from duck spare. Can you guys hear me? Yeah.\"}]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38e1149-2e58-4e40-a291-bd68e6ff0c54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speaker",
   "language": "python",
   "name": "speaker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
